{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Latent Log-likelihood"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def get_logpz(z, priors):\n",
    "    logpz = 0\n",
    "    for zi, priori in zip(z, priors):\n",
    "        if priori is None:\n",
    "            mu = jnp.zeros(zi.shape)\n",
    "            logsigma = jnp.zeros(zi.shape)\n",
    "        else:\n",
    "            mu, logsigma = jnp.split(priori, 2, axis=-1)\n",
    "        logpz += jnp.sum(- logsigma - 0.5 * jnp.log(2 * jnp.pi)\n",
    "                         - 0.5 * (zi - mu) ** 2 / jnp.exp(2 * logsigma))\n",
    "    return logpz"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dequantization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def map_fn(image_path, num_bits=5, size=256, training=True):\n",
    "    \"\"\"Read image file, quantize and map to [-0.5, 0.5] range.\n",
    "    If num_bits = 8, there is no quantization effect.\"\"\"\n",
    "    image = tf.io.decode_jpeg(tf.io.read_file(image_path))\n",
    "    # Resize input image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (size, size))\n",
    "    image = tf.clip_by_value(image, 0., 255.)\n",
    "    # Discretize to the given number of bits\n",
    "    if num_bits < 8:\n",
    "        image = tf.floor(image / 2 ** (8 - num_bits))\n",
    "    # Send to [-1, 1]\n",
    "    num_bins = 2 ** num_bits\n",
    "    image = image / num_bins - 0.5\n",
    "    if training:\n",
    "        image = image + tf.random.uniform(tf.shape(image), 0, 1. / num_bins)\n",
    "    return image\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def postprocess(x, num_bits):\n",
    "    \"\"\"Map [-0.5, 0.5] quantized images to uint space\"\"\"\n",
    "    num_bins = 2 ** num_bits\n",
    "    x = jnp.floor((x + 0.5) * num_bins)\n",
    "    x *= 256. / num_bins\n",
    "    return jnp.clip(x, 0, 255).astype(jnp.uint8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample(model,\n",
    "           params,\n",
    "           eps=None,\n",
    "           shape=None,\n",
    "           sampling_temperature=1.0,\n",
    "           key=jax.random.PRNGKey(0),\n",
    "           postprocess_fn=None,\n",
    "           save_path=None,\n",
    "           display=True):\n",
    "    \"\"\"Sampling only requires a call to the reverse pass of the model\"\"\"\n",
    "    if eps is None:\n",
    "        zL = jax.random.normal(key, shape)\n",
    "    else:\n",
    "        zL = eps[-1]\n",
    "    y, *_ = model.apply(params, zL, eps=eps, sampling_temperature=sampling_temperature, reverse=True)\n",
    "    if postprocess_fn is not None:\n",
    "        y = postprocess_fn(y)\n",
    "    plot_image_grid(y, save_path=save_path, display=display,\n",
    "                    title=None if save_path is None else save_path.rsplit('.', 1)[0].rsplit('/', 1)[1])\n",
    "    return y\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "def plot_image_grid(y, title=None, display=True, save_path=None, figsize=(10, 10)):\n",
    "    \"\"\"Plot and optionally save an image grid with matplotlib\"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    num_rows = int(np.floor(np.sqrt(y.shape[0])))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=(num_rows, num_rows), axes_pad=0.1)\n",
    "    for ax in grid:\n",
    "        ax.set_axis_off()\n",
    "    for ax, im in zip(grid, y):\n",
    "        ax.imshow(im)\n",
    "    fig.suptitle(title, fontsize=18)\n",
    "    fig.subplots_adjust(top=0.98)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    if display:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_glow(train_ds,\n",
    "               val_ds=None,\n",
    "               num_samples=9,\n",
    "               image_size=256,\n",
    "               num_channels=3,\n",
    "               num_bits=5,\n",
    "               init_lr=1e-3,\n",
    "               num_epochs=1,\n",
    "               num_sample_epochs=1,\n",
    "               num_warmup_epochs=10,\n",
    "               num_save_epochs=1,\n",
    "               steps_per_epoch=1,\n",
    "               K=32,\n",
    "               L=3,\n",
    "               nn_width=512,\n",
    "               sampling_temperature=0.7,\n",
    "               learn_top_prior=True,\n",
    "               key=jax.random.PRNGKey(0),\n",
    "               **kwargs):\n",
    "    \"\"\"Simple training loop.\n",
    "    Args:\n",
    "        train_ds: Training dataset iterator (e.g. tensorflow dataset)\n",
    "        val_ds: Validation dataset (optional)\n",
    "        num_samples: Number of samples to generate at each epoch\n",
    "        image_size: Input image size\n",
    "        num_channels: Number of channels in input images\n",
    "        num_bits: Number of bits for discretization\n",
    "        init_lr: Initial learning rate (Adam)\n",
    "        num_epochs: Numer of training epochs\n",
    "        num_sample_epochs: Visualize sample at this interval\n",
    "        num_warmup_epochs: Linear warmup of the learning rate to init_lr\n",
    "        num_save_epochs: save mode at this interval\n",
    "        steps_per_epochs: Number of steps per epochs\n",
    "        K: Number of flow iterations in the GLOW model\n",
    "        L: number of scales in the GLOW model\n",
    "        nn_width: Layer width in the Affine Coupling Layer\n",
    "        sampling_temperature: Smoothing temperature for sampling from the\n",
    "            Gaussian priors (1 = no effect)\n",
    "        learn_top_prior: Whether to learn the prior for highest latent variable zL.\n",
    "            Otherwise, assumes standard unit Gaussian prior\n",
    "        key: Random seed\n",
    "    \"\"\"\n",
    "    del kwargs\n",
    "    # Init model\n",
    "    model = GLOW(K=K,\n",
    "                 L=L,\n",
    "                 nn_width=nn_width,\n",
    "                 learn_top_prior=learn_top_prior,\n",
    "                 key=key)\n",
    "\n",
    "    # Init optimizer and learning rate schedule\n",
    "    params = model.init(random_key, next(train_ds))\n",
    "    opt = flax.optim.Adam(learning_rate=init_lr).create(params)\n",
    "\n",
    "    def lr_warmup(step):\n",
    "        return init_lr * jnp.minimum(1., step / (num_warmup_epochs * steps_per_epoch + 1e-8))\n",
    "\n",
    "    # Helper functions for training\n",
    "    bits_per_dims_norm = np.log(2.) * num_channels * image_size**2\n",
    "    @jax.jit\n",
    "    def get_logpx(z, logdets, priors):\n",
    "        logpz = get_logpz(z, priors)\n",
    "        logpz = jnp.mean(logpz) / bits_per_dims_norm        # bits per dimension normalization\n",
    "        logdets = jnp.mean(logdets) / bits_per_dims_norm\n",
    "        logpx = logpz + logdets - num_bits                  # num_bits: dequantization factor\n",
    "        return logpx, logpz, logdets\n",
    "\n",
    "    @jax.jit\n",
    "    def train_step(opt, batch):\n",
    "        def loss_fn(params):\n",
    "            _, z, logdets, priors = model.apply(params, batch, reverse=False)\n",
    "            logpx, logpz, logdets = get_logpx(z, logdets, priors)\n",
    "            return - logpx, (logpz, logdets)\n",
    "        logs, grad = jax.value_and_grad(loss_fn, has_aux=True)(opt.target)\n",
    "        opt = opt.apply_gradient(grad, learning_rate=lr_warmup(opt.state.step))\n",
    "        return logs, opt\n",
    "\n",
    "    # Helper functions for evaluation\n",
    "    @jax.jit\n",
    "    def eval_step(params, batch):\n",
    "        _, z, logdets, priors = model.apply(params, batch, reverse=False)\n",
    "        return - get_logpx(z, logdets, priors)[0]\n",
    "\n",
    "    # Helper function for sampling from random latent fixed during training for comparison\n",
    "    eps = []\n",
    "    if not os.path.exists(\"samples\"): os.makedirs(\"samples\")\n",
    "    if not os.path.exists(\"weights\"): os.makedirs(\"weights\")\n",
    "    for i in range(L):\n",
    "        expected_h = image_size // 2**(i + 1)\n",
    "        expected_c = num_channels * 2**(i + 1)\n",
    "        if i == L - 1: expected_c *= 2\n",
    "        eps.append(jax.random.normal(key, (num_samples, expected_h, expected_h, expected_c)))\n",
    "    sample_fn = partial(sample, eps=eps, key=key, display=False,\n",
    "                        sampling_temperature=sampling_temperature,\n",
    "                        postprocess_fn=partial(postprocess, num_bits=num_bits))\n",
    "\n",
    "    # Train\n",
    "    print(\"Start training...\")\n",
    "    print(\"Available jax devices:\", jax.devices())\n",
    "    print()\n",
    "    bits = 0.\n",
    "    start = time.time()\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            # train\n",
    "            for i in range(steps_per_epoch):\n",
    "                batch = next(train_ds)\n",
    "                loss, opt = train_step(opt, batch)\n",
    "                print(f\"\\r\\033[92m[Epoch {epoch + 1}/{num_epochs}]\\033[0m\"\n",
    "                      f\"\\033[93m[Batch {i + 1}/{steps_per_epoch}]\\033[0m\"\n",
    "                      f\" loss = {loss[0]:.5f},\"\n",
    "                      f\" (log(p(z)) = {loss[1][0]:.5f},\"\n",
    "                      f\" logdet = {loss[1][1]:.5f})\", end='')\n",
    "                if np.isnan(loss[0]):\n",
    "                    print(\"\\nModel diverged - NaN loss\")\n",
    "                    return None, None\n",
    "\n",
    "                step = epoch * steps_per_epoch + i + 1\n",
    "                if step % int(num_sample_epochs * steps_per_epoch) == 0:\n",
    "                    sample_fn(model, opt.target,\n",
    "                              save_path=f\"samples/step_{step:05d}.png\")\n",
    "\n",
    "            # eval on one batch of validation samples\n",
    "            # + generate random sample\n",
    "            t = time.time() - start\n",
    "            if val_ds is not None:\n",
    "                bits = eval_step(opt.target, next(val_ds))\n",
    "            print(f\"\\r\\033[92m[Epoch {epoch + 1}/{num_epochs}]\\033[0m\"\n",
    "                  f\"[{int(t // 3600):02d}h {int((t % 3600) // 60):02d}mn]\"\n",
    "                  f\" train_bits/dims = {loss[0]:.3f},\"\n",
    "                  f\" val_bits/dims = {bits:.3f}\" + \" \" * 50)\n",
    "\n",
    "            # Save parameters\n",
    "            if (epoch + 1) % num_save_epochs == 0 or epoch == num_epochs - 1:\n",
    "                with open(f'weights/model_epoch={epoch + 1:03d}.weights', 'wb') as f:\n",
    "                    f.write(flax.serialization.to_bytes(opt.target))\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nInterrupted by user at epoch {epoch + 1}\")\n",
    "\n",
    "    # returns final model and parameters\n",
    "    return model, opt.target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data hyperparameters for 1 GPU training\n",
    "# Some small changes to the original model so\n",
    "# everything fits in memory\n",
    "# In particular, I had  to use shallower\n",
    "# flows (smaller K value)\n",
    "config_dict = {\n",
    "    'image_path': \"../input/celeba-dataset/img_align_celeba/img_align_celeba\",\n",
    "    'train_split': 0.6,\n",
    "    'image_size': 64,\n",
    "    'num_channels': 3,\n",
    "    'num_bits': 5,\n",
    "    'batch_size': 64,\n",
    "    'K': 16,\n",
    "    'L': 3,\n",
    "    'nn_width': 512,\n",
    "    'learn_top_prior': True,\n",
    "    'sampling_temperature': 0.7,\n",
    "    'init_lr': 1e-3,\n",
    "    'num_epochs': 13,\n",
    "    'num_warmup_epochs': 1,\n",
    "    'num_sample_epochs': 0.2, # Fractional epochs for sampling because one epoch is quite long\n",
    "    'num_save_epochs': 5,\n",
    "}\n",
    "\n",
    "output_hw = config_dict[\"image_size\"] // 2 ** config_dict[\"L\"]\n",
    "output_c = config_dict[\"num_channels\"] * 4**config_dict[\"L\"] // 2**(config_dict[\"L\"] - 1)\n",
    "config_dict[\"sampling_shape\"] = (output_hw, output_hw, output_c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "def get_train_dataset(image_path, image_size, num_bits, batch_size, skip=None, **kwargs):\n",
    "    del kwargs\n",
    "    train_ds = tf.data.Dataset.list_files(f\"{image_path}/*.jpg\")\n",
    "    if skip is not None:\n",
    "        train_ds = train_ds.skip(skip)\n",
    "    train_ds = train_ds.shuffle(buffer_size=20000)\n",
    "    train_ds = train_ds.map(partial(map_fn, size=image_size, num_bits=num_bits, training=True))\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    train_ds = train_ds.repeat()\n",
    "    return iter(tfds.as_numpy(train_ds))\n",
    "\n",
    "\n",
    "def get_val_dataset(image_path, image_size, num_bits, batch_size,\n",
    "                    take=None, repeat=False, **kwargs):\n",
    "    del kwargs\n",
    "    val_ds = tf.data.Dataset.list_files(f\"{image_path}/*.jpg\")\n",
    "    if take is not None:\n",
    "        val_ds = val_ds.take(take)\n",
    "    val_ds = val_ds.map(partial(map_fn, size=image_size, num_bits=num_bits, training=False))\n",
    "    val_ds = val_ds.batch(batch_size)\n",
    "    if repeat:\n",
    "        val_ds = val_ds.repeat()\n",
    "    return iter(tfds.as_numpy(val_ds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, params = train_glow(train_ds, val_ds=val_ds, **config_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional, example code to load trained weights\n",
    "if False:\n",
    "    model = GLOW(K=config_dict['K'],\n",
    "                 L=config_dict['L'],\n",
    "                 nn_width=config_dict['nn_width'],\n",
    "                 learn_top_prior=config_dict['learn_top_prior'])\n",
    "\n",
    "    with open('weights/model_epoch=100.weights', 'rb') as f:\n",
    "        params = model.init(random_key, jnp.zeros((config_dict['batch_size'],\n",
    "                                                     config_dict['image_size'],\n",
    "                                                     config_dict['image_size'],\n",
    "                                                     config_dict['num_channels'])))\n",
    "        params = flax.serialization.from_bytes(params, f.read())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reconstruct(model, params, batch):\n",
    "    global config_dict\n",
    "    x, z, logdets, priors = model.apply(params, batch, reverse=False)\n",
    "    rec, *_ = model.apply(params, z[-1], z=z, reverse=True)\n",
    "    rec = postprocess(rec, config_dict[\"num_bits\"])\n",
    "    plot_image_grid(postprocess(batch, config_dict[\"num_bits\"]), title=\"original\")\n",
    "    plot_image_grid(rec, title=\"reconstructions\")\n",
    "\n",
    "\n",
    "def interpolate(model, params, batch, num_samples=16):\n",
    "    global config_dict\n",
    "    i1, i2 = np.random.choice(range(batch.shape[0]), size=2, replace=False)\n",
    "    in_ = np.stack([batch[i1], batch[i2]], axis=0)\n",
    "    x, z, logdets, priors = model.apply(params, in_, reverse=False)\n",
    "    # interpolate\n",
    "    interpolated_z = []\n",
    "    for zi in z:\n",
    "        z_1, z_2 = zi[:2]\n",
    "        interpolate = jnp.array([t * z_1 + (1 - t) * z_2 for t in np.linspace(0., 1., 16)])\n",
    "        interpolated_z.append(interpolate)\n",
    "    rec, *_ = model.apply(params, interpolated_z[-1], z=interpolated_z, reverse=True)\n",
    "    rec = postprocess(rec, config_dict[\"num_bits\"])\n",
    "    plot_image_grid(rec, title=\"Linear interpolation\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
